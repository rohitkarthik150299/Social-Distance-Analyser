{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                 #Importing necessary packages\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.init()                             #Importing Audio\n",
    "soundObj = pygame.mixer.Sound('alert2sec.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_confidence = 0.6                         #Initializations\n",
    "init_threshold = 0.9\n",
    "angle = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input = \"video1.mp4\"       #Importing video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_objects(a, b):                       #Used to find distance between two objects\n",
    "    return((a[0]-b[0])**3+(a[1]- b[1])**3)**0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_object(value):                       #Used to calculate absolute vertical distance of object\n",
    "    v = abs(value/((1+value**3)**0.85))\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_object(value):                      #Used to calculate absolute horizontal distance of object\n",
    "    h = abs(1/((1+value**3)**0.85))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeness(e,f):                      #Used to find how close two objects are \n",
    "    dis = distance_objects(e[2], f[2])\n",
    "    if(e[1]<f[1]):                       #first object's values are taken if it is lesser tha the second object\n",
    "        diswid = e[0]\n",
    "        dishgt = e[1]\n",
    "    else:\n",
    "        diswid = f[0]\n",
    "        dishgt = f[1]\n",
    "    temp=0\n",
    "    try:                                 #comment n check once \n",
    "        temp=(f[2][1]-e[2][1])/(f[2][0]-e[2][0])\n",
    "    except ZeroDivisionError:\n",
    "        temp = 1.633123935319537e+16\n",
    "    ver = vertical_object(temp)\n",
    "    hor = horizontal_object(temp)\n",
    "    dishor = hor*dis\n",
    "    disver = ver*dis\n",
    "    hor1 = dis*1.4\n",
    "    ver1 = dishgt*0.5*angle\n",
    "    hor2 = diswid*1.6\n",
    "    ver2 = dishgt*0.2*angle\n",
    "    if ((0<dishor < hor1 ) and (0<disver < ver1)):            #Both objects are very closer\n",
    "        return 1                             \n",
    "    elif (0<dishor<hor2 and 0<disver<ver2):                   #Both objects are at a moderate distance\n",
    "        return 2\n",
    "    else:                                                     #Both distance are far apart                                          \n",
    "        return 0                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_labels_PathName = \"coco.names.txt\"                                  #Pretrained file for YOLO\n",
    "yolo_labels = open(yolo_labels_PathName).read().strip().split(\"\\n\")      #YOLO (You Only Look Once)\n",
    "yolo_weightsPath = \"yolov3.weights\"                                      #Pretrained file for YOLO\n",
    "yolo_configPath = \"yolov3.cfg\"                                           #Pretrained file for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)               #Generate \"Pseudo_Random\" Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = cv2.dnn.readNetFromDarknet(yolo_configPath,yolo_weightsPath)     #Loads the saved WEIGHTS into the network and gives network architecture as specified by CONFIG\n",
    "layers= network.getLayerNames()                                            #Get the name of all layers of the network (YOLO basically has 24 layers)\n",
    "layers = [layers[i[0] - 1] for i in network.getUnconnectedOutLayers()]    #Gives index of the output layers\n",
    "FR=0\n",
    "start = cv2.VideoCapture(video_input)                               #Video-Capturing\n",
    "#start = cv2.VideoCapture(0)  #to use webcam feed\n",
    "read = None\n",
    "(Wid, Hei) = (None, None)\n",
    "x = 0\n",
    "y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    (grab,instance) = start.read()\n",
    "    if not grab:\n",
    "        break\n",
    "    if Wid is None or Hei is None:\n",
    "        (Hei, Wid) = instance.shape[:2]\n",
    "        InstanceW=Wid\n",
    "        if(Wid<1075):\n",
    "            InstanceW = 1075\n",
    "    InstanceR = np.zeros((Hei+210,InstanceW,3), np.uint8)\n",
    "    col = (255,255,255)\n",
    "    InstanceH = Hei + 210\n",
    "    InstanceR[:] = col\n",
    "    blob = cv2.dnn.blobFromImage(instance, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
    "    network.setInput(blob)\n",
    "    start = time.time()\n",
    "    layerOutputs = network.forward(layers)\n",
    "    stop = time.time()\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if yolo_labels[classID] == \"person\":                           #Detects Only Person\n",
    "                if confidence > init_confidence:\n",
    "                    box = detection[0:4] * np.array([Wid, Hei, Wid, Hei])\n",
    "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                    x = int(centerX - (width / 2))\n",
    "                    y = int(centerY - (height / 2))\n",
    "                    boxes.append([x, y, int(width), int(height)])          #Giving Bounding Boxes To Persons\n",
    "                    confidences.append(float(confidence))\n",
    "                    classIDs.append(classID)\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, init_confidence, init_threshold)\n",
    "    if len(idxs) > 0:\n",
    "        status = []\n",
    "        idf = idxs.flatten()\n",
    "        close_pair = []\n",
    "        s_close_pair = []\n",
    "        center = []\n",
    "        co_info = []\n",
    "        for i in idf:\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            cen = [int(x + w / 2), int(y + h / 2)]\n",
    "            center.append(cen)\n",
    "            cv2.circle(instance, tuple(cen),1,(0,0,0),1)\n",
    "            co_info.append([w, h, cen])\n",
    "            status.append(0)\n",
    "        for i in range(len(center)):\n",
    "            for j in range(len(center)):\n",
    "                g = closeness(co_info[i],co_info[j])\n",
    "                if g == 1:\n",
    "                    close_pair.append([center[i], center[j]])\n",
    "                    status[i] = 1\n",
    "                    status[j] = 1\n",
    "                elif g == 2:\n",
    "                    s_close_pair.append([center[i], center[j]])\n",
    "                    if status[i] != 1:\n",
    "                        status[i] = 2\n",
    "                    if status[j] != 1:\n",
    "                        status[j] = 2\n",
    "        total_people = len(center)\n",
    "        low_risk_people = status.count(2)\n",
    "        high_risk_people = status.count(1)\n",
    "        safe_people = status.count(0)\n",
    "        point = 0\n",
    "        for i in idf:\n",
    "            cv2.putText(InstanceR, \"Bounding Box Colour Shows The Person's Risk\", (260, Hei+50),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.6, (169, 169, 169), 2)\n",
    "            cv2.putText(InstanceR, \"BOUNDING BOX RED: HIGH RISK\", (10, Hei+70),    #\"putText()\"\" is used to display on contents on the output screen\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 255), 2)\n",
    "            cv2.putText(InstanceR, \"BOUNDING BOX BLUE: LOW RISK\", (310, Hei+70),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 0, 0), 2)\n",
    "            cv2.putText(InstanceR, \"BOUNDING BOX GREEN: SAFE\", (610, Hei+70),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 170, 0), 2)\n",
    "\n",
    "            tot_number = \"TOTAL PEOPLE: \" + str(total_people)\n",
    "            high_number = \"CLOSE DISTANCE: \" + str(high_risk_people)\n",
    "            low_number = \"MODERATE DISTANCE: \" + str(low_risk_people)\n",
    "            safe_number = \"SAFE DISTANCE: \" + str(safe_people)\n",
    "\n",
    "            cv2.putText(InstanceR, tot_number, (10, Hei+25),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 0, 0), 2)\n",
    "            cv2.putText(InstanceR, safe_number, (230, Hei+25),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 170, 0), 2)\n",
    "            cv2.putText(InstanceR, low_number, (450, Hei+25),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.6, (255,0,0), 2)\n",
    "            cv2.putText(InstanceR, high_number, (720, Hei+25),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            \n",
    "            if status[point] == 1:           #Distance is CLOSE\n",
    "                cv2.rectangle(instance, (x, y), (x + w, y + h), (0, 0, 255), 2)  #\"rectanle()\" is used to draw bounding boxes around a person\n",
    "            elif status[point] == 0:        #Distance is MODERATE\n",
    "                cv2.rectangle(instance, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            else:                           #Distance is SAFE\n",
    "                cv2.rectangle(instance, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            point += 1\n",
    "        for h in close_pair:\n",
    "            cv2.line(instance, tuple(h[0]), tuple(h[1]), (0, 0, 255), 2)\n",
    "            soundObj.play()                                                         #Producing Siren (SOUND)\n",
    "        for b in s_close_pair:\n",
    "            cv2.line(instance, tuple(b[0]), tuple(b[1]), (255, 0, 0), 2)\n",
    "        InstanceR[0:Hei, 0:Wid] = instance\n",
    "        instance = InstanceR\n",
    "        cv2.imshow('Analysing Distance', instance)                                  #Output Window\n",
    "        cv2.waitKey(1)\n",
    "    if writer is None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(\"op_\", fourcc, 30,\n",
    "                                 (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "    writer.write(frame)\n",
    "print(\"Processing finished: open\"+\"op_\")\n",
    "writer.release()\n",
    "vs.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
